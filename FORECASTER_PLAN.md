FORECASTER_MASTER_PLAN.md

âœ” Fully self-contained
âœ” No conversation references
âœ” Clear architecture
âœ” Exact file + function expectations
âœ” Implements everything youâ€™ve built
âœ” Lays out the future roadmap cleanly

â¸»

BloombergGPT Forecaster Pipeline â€” Master Plan

This document defines the architecture, phases, responsibilities, and file structure for the semantic + numeric forecasting system. It is written so that any future LLM (Codex, GPT, etc.) can reconstruct and continue development with zero reliance on conversation history.

â¸»

Objectives 1. Collect real numeric market returns. 2. Build features from:
â€¢ price history
â€¢ event embeddings
â€¢ simple statistical signals 3. Train a return forecaster for assets (initially BTC, ETH, XMR). 4. Expose predictions via a FastAPI backend. 5. Integrate semantic events with numeric forecasting.

Everything below details how each objective should be implemented.

â¸»

System Overview

The system has two independent data domains, merged only inside the forecaster.

â¸»

1. Events (Semantic Text Domain)

Stored in the events table via RSS ingestion.

Each event row contains:
â€¢ id
â€¢ timestamp
â€¢ source
â€¢ url
â€¢ title
â€¢ summary
â€¢ raw_text
â€¢ clean_text
â€¢ categories
â€¢ tags
â€¢ pgvector embedding (embed)

Nearest neighbor semantic search using:

SELECT ... ORDER BY embed <-> anchor LIMIT k ;

API:

GET /events/{event_id}/similar

â¸»

2. Numeric Returns (Market Data Domain)

Stored in the asset_returns table.

Inserted via Yahoo Finance:
â€¢ BTC-USD
â€¢ ETH-USD
â€¢ XMR-USD

Schema:

(symbol TEXT,
as_of TIMESTAMPTZ,
horizon_minutes INT,
realized_return DOUBLE PRECISION,
price_start DOUBLE PRECISION,
price_end DOUBLE PRECISION)

Primary uniqueness constraint:

UNIQUE (symbol, as_of, horizon_minutes)

These two domains merge during forecasting.

â¸»

Forecasting Pipeline Phases

â¸»

PHASE 1 â€” Backfill Numeric Returns (Complete)

ğŸ“„ File: backend/ingest/backfill_crypto_returns.py

Responsibilities: 1. Download daily OHLC for 365+ days. 2. Convert timestamps â†’ UTC. 3. For each consecutive (t0 â†’ t1):
â€¢ realized_return = (p1/p0) âˆ’ 1
â€¢ insert via insert_asset_return() 4. Store rows in asset_returns.

This phase populates the numeric â€œtape.â€

Status: âœ” Complete

â¸»

PHASE 2 â€” Feature Extraction

This phase builds model features from both numeric & semantic data.

There are three feature groups:

â¸»

A. Price Features (Numeric)

ğŸ“„ File: backend/signals/price_context.py

Function to implement:

def build_price_features(symbol: str, as_of: datetime) -> Dict[str, float]:

Features:
â€¢ previous 1-day return
â€¢ 3-day / 7-day / 14-day / 30-day cumulative returns
â€¢ rolling volatility
â€¢ rolling z-score
â€¢ momentum proxies
â€¢ max drawdown window

Inputs: asset_returns
Outputs: numeric dict

â¸»

B. Event Embedding Features (Semantic)

ğŸ“„ File: backend/signals/context_window.py

Function to implement:

def build_event_features(symbol: str, as_of: datetime) -> Dict[str, float]:

Features:
â€¢ count of events in last 1d / 3d / 7d
â€¢ share of AI-related events
â€¢ distinct sources
â€¢ hours since last event
â€¢ aggregate embedding statistics (Phase 3+)
â€¢ similarity to â€œtrend upâ€ and â€œtrend downâ€ centroids (future work)

These features connect semantic activity to the numeric world.

â¸»

C. Regime Classification (Optional but Recommended)

ğŸ“„ File: backend/models/regime_classifier.py

Goal: label market regime around as_of:
â€¢ uptrend
â€¢ downtrend
â€¢ chop / consolidation
â€¢ high-volatility

API:

def classify_regime(symbol: str, as_of: datetime) -> str:

Used as a categorical input to future ML models.

â¸»

PHASE 3 â€” Forecasting Models

ğŸ“‚ Directory: backend/models/

Two forecasters are used in parallel:

â¸»

1. Naive Baseline Forecaster

ğŸ“„ models/naive_asset_forecaster.py

Purpose: sanity check.

pred_return = mean(last_N_realized_returns)

API:

def forecast_asset(symbol: str, as_of: datetime, horizon_minutes: int, lookback_days: int = 60) -> ForecastResult

If ML cannot beat this â†’ model is wrong.

â¸»

2. Event Return Forecaster (Semantic â†’ Numeric Conditioning)

ğŸ“„ models/event_return_forecaster.py

Steps: 1. Take given event_id 2. Find k nearest events via pgvector 3. For each neighbor, fetch the assetâ€™s realized return after its timestamp 4. Weight each return by exp(âˆ’Î± \* distance) 5. Compute:
â€¢ expected_return
â€¢ std_return
â€¢ p_up / p_down
â€¢ neighbor count

API:

def forecast_event_return(event_id, symbol, horizon_minutes, ...)

This is the first â€œsemantic marketsâ€ signal.

â¸»

PHASE 4 â€” Forecast API Endpoint

ğŸ“„ File: backend/app.py

Add:

1. Baseline Asset Endpoint

GET /forecast/asset?symbol=BTC-USD&horizon_minutes=1440

Output:

{
"symbol": "BTC-USD",
"horizon_minutes": 1440,
"mean_return": ...,
"std_return": ...,
"p_up": ...,
"p_down": ...,
"sample_size": ...
}

2. Event-Conditioned Endpoint

GET /forecast/event/{event_id}?symbol=BTC-USD

Output:

{
"event_id": "...",
"symbol": "BTC-USD",
"expected_return": ...,
"std_return": ...,
"p_up": ...,
"p_down": ...,
"sample_size": ...,
"neighbors_used": ...
}

This merges price action + semantic similarity.

â¸»

PHASE 5 â€” Event + Price Fusion (Future Work)

The ultimate goal:
A hybrid model that conditions price forecasts on semantic meaning.

Work required: 1. PCA or pooling of event embeddings 2. Vectorized event context window 3. Combine with numeric features 4. Fit ML model (RandomForest, XGBoost) 5. Predict:
â€¢ expected_return
â€¢ confidence
â€¢ direction

This unlocks behavior such as:

â€œAI regulation headlines tend to depress ETH on next-day returns.â€

This is the foundation of a true semantic markets engine.

â¸»

File Structure Summary

backend/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ db.py
â”œâ”€â”€ embeddings.py
â”‚
â”œâ”€â”€ ingest/
â”‚ â”œâ”€â”€ rss_ingest.py
â”‚ â””â”€â”€ backfill_crypto_returns.py
â”‚
â”œâ”€â”€ numeric/
â”‚ â””â”€â”€ asset_returns.py
â”‚
â”œâ”€â”€ signals/
â”‚ â”œâ”€â”€ price_context.py
â”‚ â”œâ”€â”€ context_window.py
â”‚ â”œâ”€â”€ feature_extractor.py
â”‚ â”œâ”€â”€ matchup_signals.py
â”‚ â”œâ”€â”€ curry_signals.py
â”‚ â”œâ”€â”€ fatigue_signals.py
â”‚ â””â”€â”€ team_news_signals.py
â”‚
â””â”€â”€ models/
â”œâ”€â”€ naive_asset_forecaster.py
â”œâ”€â”€ event_return_forecaster.py
â””â”€â”€ regime_classifier.py

â¸»

Key Implementation Rules 1. Use UTC everywhere. 2. Never use future information (strict timestamp discipline). 3. Event â†’ price alignment always uses the event timestamp. 4. Embeddings must be generated from clean_text. 5. Numeric returns must maintain

UNIQUE(symbol, as_of, horizon_minutes)

    6.	Baseline numeric model first, ML model second.
    7.	Limit semantic features to past events only.
    8.	Avoid leaking future prices when building features.
    9.	Keep the system modular so new assets / event sources are trivial to add.

â¸»

End of Document

This markdown file is self-contained, authoritative, and sufficient for a future LLM to fully reconstruct the forecaster system without needing historical chat context.

Let me know if you want a TRAINING_PLAN.md, API_SPEC.md, or ARCHITECTURE_DIAGRAM.md.
